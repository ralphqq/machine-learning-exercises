{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification with Logistic Regression\n",
    "This notebook makes use of logistic regression to come up with a multi-class classification model that tries to recognize handwritten digits. This is part one of exercise 3 in Prof. Ng's class and I'm closely following the [Python implementation](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-4/) provided by John Wittenhauer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "The data file is in a special Matlab matrix format, so we use a scipy function for handling this sort of file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('Data/ex04data1.mat')\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " '__globals__': [],\n",
       " '__header__': 'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ..., \n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data` variable points to a dict whose values are the `X` and `y` nd-arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 400)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the exercise text, the `X` nd-array can be understood as follows:\n",
    "> There are 5000 training examples in [ex04data1.mat], where each training example is a 20 pixel by 20 pixel grayscale image of the digit. Each pixel is represented by a floating point number indicating the grayscale intensity at that location. The 20 by 20 grid of pixels is \"unrolled\" into a 400-dimensional vector. Each of these training examples becomes a single row in our data matrix X. This gives us a 5000 by 400 matrix X where every row is a training example for a handwritten digit image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `y` nd-array contains the training labels for our training sample. According to the exercise text, the label of the digit '0' is actually set to 10 in order to avoid confusion with indexing since Matlab uses 1-indexing instead of 0-indexing.\n",
    "So, to check whether the `y` dn-array contains the labels we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.unique(data['y'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nclasses = len(labels)\n",
    "nclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Sigmoid, Cost, and Gradient Functions\n",
    "The sigmoid, cost, and gradient functions from the previous exercise are used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Regularized Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y, regrate=1):\n",
    "    theta = np.matrix(theta).T\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    m, _ = y.shape\n",
    "    z = X * theta\n",
    "    cost_i = np.log(sigmoid(z)) + np.diag(y.A1 - 1) * z\n",
    "    reg_term = (regrate * np.sum(np.power(theta[1:], 2))) / (2 * m)\n",
    "    return ((-np.sum(cost_i)) / m) + reg_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Gradient Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, regrate=1):\n",
    "    theta = np.matrix(theta).T\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    m = y.shape[0]\n",
    "    n = theta.shape[0]\n",
    "    \n",
    "    z = X * theta\n",
    "    \n",
    "    reg_vec = np.matrix(np.zeros(shape=(n, 1)))\n",
    "    reg_vec[1:] = regrate\n",
    "    reg_diag = np.eye(n) * reg_vec\n",
    "    \n",
    "    grad = (X.T * (sigmoid(z) - y)) + reg_diag\n",
    "    return (grad.A1) / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-vs-all Classification\n",
    "Since our objective is to classify handwritten digits from '0' to '9', we need to estimate 10 different classifiers (one for each digit).\n",
    "\n",
    "The below function should return all the classifier parameters in a matrix `theta_all` where each row of `theta_all` corresponds to the learned logistic regression parameters for one class. (The below approach is very similar to the one implemented by John Wittenhauer in [part 4 of his ML blog series](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-4/).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_vs_all(X, y, nclasses, regrate=1):\n",
    "    nrows, nparams = X.shape\n",
    "    \n",
    "    # This is the k x (n + 1) matrix of all of the estimated coeffs\n",
    "    # where k is the number of classes (labels)\n",
    "    # n is the number of params\n",
    "    # n + 1 is used to include the intercecpt param\n",
    "    theta_all = np.zeros((nclasses, nparams + 1))\n",
    "    \n",
    "    # inserting a ones column for the intercept term\n",
    "    X = np.insert(X, 0, values=np.ones(nrows), axis=1)\n",
    "    \n",
    "    # estimating each of the nclasses classifiers\n",
    "    for i in range(nclasses):\n",
    "        # '0' is represented as 10 in the data set\n",
    "        digit = i + 1\n",
    "        \n",
    "        # This creates an nrows x 1 array which contains\n",
    "        # 1 in the mth element if the label in mth elem of y is equal to `digit`\n",
    "        # 0 otherwise\n",
    "        y_digit = y == digit\n",
    "        y_digit = y_digit.astype(int)   # convert bool to int\n",
    "        \n",
    "        # minimize the objective func\n",
    "        fmin = minimize(fun=cost, x0=theta_all[i],\n",
    "                        args=(X, y_digit, regrate), method='TNC',\n",
    "                        jac=gradient)\n",
    "        \n",
    "        theta_all[i] = fmin.x\n",
    "    \n",
    "    return theta_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Optimal Thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_all = one_vs_all(X=data['X'], y=data['y'], nclasses=nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 401)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.62490239, -0.21277825, -0.21277825, ..., -0.21250584,\n",
       "        -0.21277796, -0.21277825],\n",
       "       [-1.80262264, -0.38890201, -0.38890201, ..., -0.38676592,\n",
       "        -0.38914839, -0.38890201],\n",
       "       [-3.9025954 , -0.34165007, -0.34165007, ..., -0.34166276,\n",
       "        -0.34164997, -0.34165007],\n",
       "       ..., \n",
       "       [-7.10545462, -0.33453415, -0.33453415, ..., -0.33460472,\n",
       "        -0.3345285 , -0.33453415],\n",
       "       [-3.55434963, -0.31415108, -0.31415108, ..., -0.31450722,\n",
       "        -0.314125  , -0.31415108],\n",
       "       [-2.71456744, -0.55210593, -0.55210593, ..., -0.55147119,\n",
       "        -0.55208727, -0.55210593]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Handwritten Digits\n",
    "We now use the estimated values for our parameters in our set of logistic classifiers to identify a given handwritten digit. To do this we apply each of the 10 classifiers we estimated on each of the training sample and choose the classifier which gives  the highest sigmoid as the correct one for that particular example. This is implemented in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_digit(X, theta_all):\n",
    "    nrows, _ = X.shape\n",
    "    \n",
    "    X = np.insert(X, 0, values=np.ones(nrows), axis=1)\n",
    "    \n",
    "    X = np.matrix(X)\n",
    "    theta_all = np.matrix(theta_all)\n",
    "    \n",
    "    # sigmoid for each class on a given training example\n",
    "    # Each row of h contains the 10 sigmoids for that example\n",
    "    h = sigmoid(X * theta_all.T)\n",
    "    \n",
    "    max_h_index = np.argmax(h, axis=1)\n",
    "    \n",
    "    return max_h_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = identify_digit(data['X'], theta_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        [10],\n",
       "        [10]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [9],\n",
       "        [7]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.679999999999993"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, _ = y_hat.shape\n",
    "correct = data['y'] == y_hat\n",
    "accuracy = (np.sum(correct.astype(float)) / m) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, not bad for a first try, I guess. Prof. Ng's and Mr. Wittenhauer's accuracy values for this exercise are 95% and 98%, respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
