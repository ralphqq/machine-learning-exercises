{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "This covers exercise 3 of Prof. Andrew Ng's ML Stanford course and closely follows part 3 of [John Wittenhauer's Python rendering of the exercise](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/). I tried playing around with the approach to the problem and used matrix operations in place of `for` loops and explicit element-wise multiplication, though I don't think my approach is any better.\n",
    "## Logistic Regression Classification\n",
    "The objective of exercise three is to come up with a model that can predict whether a given student will be admitted to a school based on the candidate's scores on two exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('Data\\\\ex03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "      <th>admitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       exam1      exam2  admitted\n",
       "0  34.623660  78.024693         0\n",
       "1  30.286711  43.894998         0\n",
       "2  35.847409  72.902198         0\n",
       "3  60.182599  86.308552         1\n",
       "4  79.032736  75.344376         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admitted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0</th>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.032301</td>\n",
       "      <td>54.620392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.549050</td>\n",
       "      <td>16.081591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.058822</td>\n",
       "      <td>30.603263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.707085</td>\n",
       "      <td>42.808798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.410642</td>\n",
       "      <td>49.698756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.928323</td>\n",
       "      <td>63.594638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.861555</td>\n",
       "      <td>98.869436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>74.718923</td>\n",
       "      <td>73.956402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.912420</td>\n",
       "      <td>16.012403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.457551</td>\n",
       "      <td>43.390602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.597244</td>\n",
       "      <td>65.409676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75.436657</td>\n",
       "      <td>74.753748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>84.675745</td>\n",
       "      <td>87.442625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.827858</td>\n",
       "      <td>97.718692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    exam1      exam2\n",
       "admitted                            \n",
       "0        count  40.000000  40.000000\n",
       "         mean   52.032301  54.620392\n",
       "         std    17.549050  16.081591\n",
       "         min    30.058822  30.603263\n",
       "         25%    35.707085  42.808798\n",
       "         50%    50.410642  49.698756\n",
       "         75%    61.928323  63.594638\n",
       "         max    95.861555  98.869436\n",
       "1        count  60.000000  60.000000\n",
       "         mean   74.718923  73.956402\n",
       "         std    14.912420  16.012403\n",
       "         min    40.457551  43.390602\n",
       "         25%    63.597244  65.409676\n",
       "         50%    75.436657  74.753748\n",
       "         75%    84.675745  87.442625\n",
       "         max    99.827858  97.718692"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = data1.groupby(by='admitted')\n",
    "groups.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admitted\n",
       "0    52.032301\n",
       "1    74.718923\n",
       "Name: exam1, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.exam1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admitted\n",
       "0    54.620392\n",
       "1    73.956402\n",
       "Name: exam2, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.exam2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see that the mean `exam1` and `exam2` scores are higher in the addmited group (candidates with 1 under the `admitted` column) and the not admitted candidates.\n",
    "\n",
    "This is shown more clearly in the below figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x40e2c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAEVCAYAAAD3k38NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGgAAYD0CDQAAsN7/ASik6LDlPGXJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7e30710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.factorplot(data=data1, col='admitted', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's just look at the raw scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f80930>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAFdCAYAAADyh0G5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f807f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x='exam1', y='exam2', hue='admitted', data=data1, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like an applicant's scores might predict whether he or she gets admitted. Now let's proceed with our logistic regression analysis using these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sigmoid Function\n",
    "As shown in the lectures, the hypothesis function for a logistic regression problem is best stated as a sigmoid function as follows:\n",
    "\n",
    "$$ {h_\\theta }\\left( {{{\\bf{x}}_i}} \\right) = g\\left( z \\right) = \\frac{1}{{1 + {e^{ - z}}}} $$\n",
    "\n",
    "where: $ z = {\\theta ^T}{{\\bf{x}}_i} $\n",
    "\n",
    "Thus we define the following function in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cost Function\n",
    "The individual cost function for the $ i $-th training sample is given by:\n",
    "\n",
    "$$ {\\rm{cost}}\\left( {{h_\\theta }\\left( {{{\\bf{x}}_i}} \\right),\\,{y_i}} \\right) =  - {y_i}\\ln {h_\\theta }\\left( {{{\\bf{x}}_i}} \\right) - \\left( {1 - {y_i}} \\right)\\ln \\left( {1 - {h_\\theta }\\left( {{{\\bf{x}}_i}} \\right)} \\right) $$\n",
    "\n",
    "The overall cost for $ m $ training samples is:\n",
    "\n",
    "$$ J\\left( \\theta  \\right) =  - \\frac{1}{m}\\sum\\limits_{i = 1}^m {\\left[ {{y_i}\\ln {h_\\theta }\\left( {{{\\bf{x}}_i}} \\right) - \\left( {1 - {y_i}} \\right)\\ln \\left( {1 - {h_\\theta }\\left( {{{\\bf{x}}_i}} \\right)} \\right)} \\right]}  $$\n",
    "\n",
    "This can further be simplified into:\n",
    "\n",
    "$$ J\\left( \\theta  \\right) =  - \\frac{1}{m}\\sum\\limits_{i = 1}^m {\\left[ {\\ln {h_\\theta }\\left( {{{\\bf{x}}_i}} \\right) + \\left( {{y_i} - 1} \\right){\\theta ^T}{{\\bf{x}}_i}} \\right]}  $$\n",
    "\n",
    "I think the above simplification is more tenable to vectorization later on, especially if we consider that the whole business inside the summation operator can be expressed in matrix form as follows:\n",
    "\n",
    "$$ {\\rm{\\gamma }} + \\left( {{\\bf{y}} - {\\bf{1}}} \\right){{\\bf{I}}_m}{\\bf{X}}\\theta  = \\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill {\\ln {\\theta ^T}{{\\bf{x}}_1}} \\\\\n",
    "   \\hfill {\\ln {\\theta ^T}{{\\bf{x}}_2}} \\\\\n",
    "   \\hfill  \\vdots  \\\\\n",
    "   \\hfill {\\ln {\\theta ^T}{{\\bf{x}}_m}} \\\\\n",
    "\\end{array}} \\right] + \\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill {{y_1} - 1} & \\hfill {} & \\hfill {} & \\hfill {} \\\\\n",
    "   \\hfill {} & \\hfill {{y_2} - 1} & \\hfill {} & \\hfill {} \\\\\n",
    "   \\hfill {} & \\hfill {} & \\hfill  \\ddots  & \\hfill {} \\\\\n",
    "   \\hfill {} & \\hfill {} & \\hfill {} & \\hfill {{y_m} - 1} \\\\\n",
    "\\end{array}} \\right]\\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill {{\\theta ^T}{{\\bf{x}}_1}} \\\\\n",
    "   \\hfill {{\\theta ^T}{{\\bf{x}}_2}} \\\\\n",
    "   \\hfill  \\vdots  \\\\\n",
    "   \\hfill {{\\theta ^T}{{\\bf{x}}_m}} \\\\\n",
    "\\end{array}} \\right] $$\n",
    "\n",
    "where $ \\gamma  = {\\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill {\\ln {\\theta ^T}{{\\bf{x}}_1}} & \\hfill {\\ln {\\theta ^T}{{\\bf{x}}_2}} & \\hfill  \\ldots  & \\hfill {\\ln {\\theta ^T}{{\\bf{x}}_m}} \\\\\n",
    "\\end{array}} \\right]^T} $ , $ {\\bf{1}} $ is an $ m $ -dimensional vector whose components are all 1, and $ {{\\bf{I}}_m}$ is the $ m \\times m $ identity matrix.\n",
    "\n",
    "So, we define the following overall cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    theta = np.matrix(theta).T\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    m, _ = y.shape\n",
    "    z = X * theta\n",
    "    cost_i = np.log(sigmoid(z)) + np.diag(y.A1 - 1) * z\n",
    "    return (-np.sum(cost_i)) / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn Everything to Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target variable\n",
    "m, _ = data1.shape\n",
    "y = np.reshape(data1.admitted.values, (m, 1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the array for the design matrix\n",
    "ones = np.ones(m)\n",
    "exam1 = data1.exam1.values\n",
    "exam2 = data1.exam2.values\n",
    "X = np.array([ones, exam1, exam2]).T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining and initializing the parameter vector theta\n",
    "_, nparams = X.shape\n",
    "theta = np.zeros(nparams)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out the Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69314718055994529"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(X=X, y=y, theta=theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient and Optimization\n",
    "Based on the equation for $ J\\left( \\theta  \\right) $, we can show that the gradient descent for finding the value of $ j $ -th parameter that minimizes the overall cost function is:\n",
    "\n",
    "$$ {\\theta _j}: = {\\theta _j} - \\alpha \\frac{\\partial }{{\\partial {\\theta _j}}}J\\left( \\theta  \\right) $$\n",
    "\n",
    "which turns out to be:\n",
    "\n",
    "$$ {\\theta _j}: = {\\theta _j} - \\alpha \\frac{1}{m}\\sum\\limits_{i = 1}^m {{{\\bf{x}}_i}\\left[ {{h_\\theta }\\left( {{{\\bf{x}}_i}} \\right) - {y_i}} \\right]}  $$\n",
    "\n",
    "This looks exactly like the gradient descent algorithm we saw for linear regression.\n",
    "\n",
    "Note that the (gradient term) summation term can be expressed in matrixx form as:\n",
    "\n",
    "$$ \\sum\\limits_{i = 1}^m {{{\\bf{x}}_i}\\left[ {{h_\\theta }\\left( {{{\\bf{x}}_i}} \\right) - {y_i}} \\right]}  = {{\\bf{X}}^T}\\left[ {{\\rm{\\gamma }} - {\\bf{y}}} \\right] $$\n",
    "\n",
    "where \n",
    "\n",
    "$$ {\\rm{\\gamma }} = \\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill {g\\left( {{\\theta ^T}{{\\bf{x}}_i}} \\right)} \\\\\n",
    "   \\hfill {g\\left( {{\\theta ^T}{{\\bf{x}}_2}} \\right)} \\\\\n",
    "   \\hfill  \\vdots  \\\\\n",
    "   \\hfill {g\\left( {{\\theta ^T}{{\\bf{x}}_m}} \\right)} \\\\\n",
    "\\end{array}} \\right] = \\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill {{h_\\theta }\\left( {{{\\bf{x}}_1}} \\right)} \\\\\n",
    "   \\hfill {{h_\\theta }\\left( {{{\\bf{x}}_2}} \\right)} \\\\\n",
    "   \\hfill  \\vdots  \\\\\n",
    "   \\hfill {{h_\\theta }\\left( {{{\\bf{x}}_m}} \\right)} \\\\\n",
    "\\end{array}} \\right] $$\n",
    "\n",
    "This will make it easier to write our gradient function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    theta = np.matrix(theta).T\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    z = X * theta\n",
    "    grad = X.T * (sigmoid(z) - y)\n",
    "    return (grad.A1) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the [approach used by J. Wittenhauer](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/) and by Prof. Ng in this exercise, we do not explicitly write the iterations needed to arrive at the optimal values of the parameters. Rather we write the above function to return the gradient at specific values of the parameters and let scipy's optimization API compute the optimal values of theta for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.1       , -12.00921659, -11.26284221])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's give this a try\n",
    "gradient(X=X, y=y, theta=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-25.1613185 ,   0.20623159,   0.20147148]), 36, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, y))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20349770158938385"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(theta=res[0], X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is certainly lower than the initial cost of 0.69. According to the optimization algorithm we used, the values of the parameters (`theta`) that give the minimum possible cost are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-25.1613185 ,   0.20623159,   0.20147148])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model and Making Predictions\n",
    "We now have the parameters we need to build our model for predicting if a student gets admitted or not. The results show that\n",
    "\n",
    "$$ {z_i} = {\\hat \\theta ^T}{{\\bf{x}}_i} = {\\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill { - 25.161} \\\\\n",
    "   \\hfill {0.206} \\\\\n",
    "   \\hfill {0.201} \\\\\n",
    "\\end{array}} \\right]^T}\\left[ {\\begin{array}{*{20}{c}}\n",
    "   \\hfill 1 \\\\\n",
    "   \\hfill {{x_{i,1}}} \\\\\n",
    "   \\hfill {{x_{i,2}}} \\\\\n",
    "\\end{array}} \\right] =  - 25.161 + 0.206{x_{i,1}} + 0.201{x_i}_{,2} $$\n",
    "\n",
    "where $ \\hat \\theta  $ is the vector of our estimated parameters and $ {x_{i,1}} $ and $ {x_{i,2}} $ are the $ i $-th student's scores on the first and second exams, respectively.\n",
    "\n",
    "We can now make the following predictions:\n",
    "\n",
    "$$ {\\hat y_i} = \\left\\{ \\begin{array}{l}\n",
    " 1{\\rm{      if  }}{z_i} > 0 \\\\ \n",
    " 0{\\rm{     otherwise}} \\\\ \n",
    " \\end{array} \\right. $$\n",
    " \n",
    "which is equivalent to:\n",
    "\n",
    "$$ {\\hat y_i} = \\left\\{ \\begin{array}{l}\n",
    " 1{\\rm{      if  }}g\\left( {{z_i}} \\right) > 0.5 \\\\ \n",
    " 0{\\rm{     otherwise}} \\\\ \n",
    " \\end{array} \\right. $$\n",
    "\n",
    "But we'll just use the first one so that we won't need to call the sigmoid function. Thus, our function for prediction is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta_hat, X):\n",
    "    theta_hat = np.matrix(theta_hat).T\n",
    "    X = np.matrix(X)\n",
    "    z = X * theta_hat\n",
    "    y_hat = z > 0\n",
    "    return y_hat.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = predict(theta_hat=res[0], X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy of prediction\n",
    "y_hat = np.reshape(y_hat, (len(y_hat), 1))       # turn y_hat into mx1\n",
    "correct = y == y_hat\n",
    "accuracy = (np.sum(correct.astype(float)) / m) * 100\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
